
# Assignment 01 of 10: Real-World Applications of Machine Learning and Data Analysis
## ML Application ğŸ¤– - Sarcasm Detection in News Headlines ğŸ“°

## ğŸ¤” Introduction

Sarcasm detection in text is tricky! ğŸ˜‰ Unlike regular sentiment analysis (positive/negative/neutral), sarcasm uses irony, making interpretation hard. This project uses **Deep Learning** to detect sarcasm in news headlines from *TheOnion* (sarcastic) & *HuffPost* (non-sarcastic).

**Goal:** Build & evaluate a model to classify headlines, understand its real-world use, and explore future improvements. Knowing sarcasm helps analyze social media, customer feedback, etc., more accurately. ğŸ‘

## ğŸ’¾ Dataset: "News Headline Dataset for Sarcasm Detection"

*   **Source:** [GitHub Repository](https://github.com/rishabhmisra/News-Headlines-Dataset-For-Sarcasm-Detection) ğŸ’»
*   **Content:** Headlines from *TheOnion* (sarcastic) & *HuffPost* (non-sarcastic).
*   **Structure:**
    *   `is_sarcastic`: Binary label (1 = sarcastic, 0 = not).
    *   `headline`: The actual news headline text. ğŸ“
    *   `article_link`: URL to the original article (optional context). ğŸ”—
*   **Why this dataset?** Professionally written (fewer errors), high-quality sarcastic examples from TheOnion, self-contained headlines. âœ…

*Used `Sarcasm_Headlines_Dataset_v2.json` for this project.*

## ğŸ› ï¸ Training Process: Deep Learning Approach

1.  **Load Data:** Read headlines from the JSON file. ğŸ“¥
2.  **Preprocess Text:**
    *   **Tokenize:** Convert words into numerical sequences (using Keras Tokenizer).
    *   **Pad Sequences:** Ensure all sequences have the same length for model input. ğŸ“
3.  **Build Model Architecture:** ğŸ§ 
    *   **Embedding Layer:** Learns word meanings/relationships.
    *   **Global Average Pooling 1D:** Reduces sequence data to a fixed vector.
    *   **Dense Layers:** Learns complex patterns from features.
    *   **Output Layer:** Sigmoid activation for binary (sarcastic/not) probability output. ğŸ¯
4.  **Optimize & Regularize:** To prevent overfitting:
    *   **Early Stopping:** Stops training when performance on validation data stops improving. ğŸ›‘
    *   **L2 Regularization:** Penalizes large weights.
    *   **Dropout:** Randomly ignores some neurons during training. âœ¨

*The best results came from using **Early Stopping** and **Dropout**.*

## ğŸ‰ Results & Key Findings

*   **Performance:** Achieved **~90% accuracy** on the test set! ğŸ†
*   **Insights:**
    *   Embedding layers successfully captured semantic nuances. âœ¨
    *   Regularization (Dropout, Early Stopping) significantly improved generalization. ğŸ’ª
    *   Model is effective but struggles with highly ambiguous or context-dependent sarcasm. ğŸ¤”

### ğŸ“Š Example Predictions

*   `Have no fear of perfection, you'll never reach it.` --> **Sarcastic (72.73%)** ğŸ˜‚
*   `I like long walks, especially when they are taken by people who annoy me` --> **Sarcastic (15.88%)** ğŸš¶â€â™€ï¸ğŸ’¨ *(Note: Lower confidence shows nuance)*
*   `I am so clever that sometimes I do not understand a single word of what I am saying.` --> **Not Sarcastic (0.23%)** ğŸ¤” *(Example of correct classification)*

## ğŸŒ Real-World Applications

Detecting sarcasm improves:

*   ğŸ‘€ **Social Media Monitoring:** Understand true user sentiment.
*   ğŸ—£ï¸ **Customer Feedback Analysis:** Filter genuine vs. ironic comments.
*   ğŸ“° **News Aggregation:** Identify or filter satirical sources.
*   ğŸ¤– **Chatbots/Virtual Assistants:** Respond more appropriately.
*   ğŸ¬ **Content Recommendation:** Suggest relevant satirical/non-satirical content.

## ğŸš€ Future Enhancements

Potential improvements:

1.  **More Context:** Use full articles, not just headlines. ğŸ“–
2.  **Multimodal Data:** Include images/video tone if available. ğŸ–¼ï¸ğŸ”Š
3.  **Transfer Learning:** Use pre-trained models like BERT/GPT. ğŸ¤–
4.  **Explainability (XAI):** Understand *why* the model makes a decision. ğŸ’¡
5.  **Cross-Domain Testing:** Check performance on tweets, reviews, etc. ğŸ”„

## âœ… Conclusion

This project successfully demonstrated using deep learning to detect sarcasm in news headlines with ~90% accuracy. It highlights the importance of understanding nuanced language in text analysis. While effective, future work incorporating more context, advanced models, and explainability can further improve robustness. ğŸ‰

## ğŸ¤ Acknowledgements

This work is carried out under the valuable guidance of  
**[Dr Agughasi Victor Ikechukwu](https://github.com/Victor-Ikechukwu)**. 

His mentorship has been instrumental in ensuring the academic quality and depth of these assignments.

---

## ğŸ“¬ Contact

- ğŸ‘¤ **Author**: Thilak R
- ğŸ“§ **Email**: [thilak22005@gmail.com](mailto:thilak22005@gmail.com)
- ğŸŒ **GitHub**: [thilak-r](https://github.com/thilak-r)
